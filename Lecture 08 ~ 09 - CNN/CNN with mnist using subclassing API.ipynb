{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN with mnist using subclassing API.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# CNN with mnist using subclassing API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3y_Dooe9Ha7",
        "outputId": "12e3b4cf-1b78-453c-f170-addd4c47b6d8"
      },
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__) # find the version number (should be 2.x+)\n",
        "\n",
        "# 그래피카드 유무 확인 및 메모리 확장 설정\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  print('사용가능한 GPU 갯수: ',len(gpus), '\\n')\n",
        "      \n",
        "  try:\n",
        "    # 프로그램이 실행되어 더 많은 GPU 메모리가 필요하면, 텐서플로 프로세스에 할당된 GPU 메모리 \n",
        "    # 영역을 확장할 수있도록 허용\n",
        "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "\n",
        "  except RuntimeError as e:\n",
        "    # 프로그램 시작시에 접근 가능한 장치가 설정되어야만 합니다\n",
        "    print(e)\n",
        "\n",
        "# 설치된 GPU 상세내용 확인\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.6.0\n",
            "사용가능한 GPU 갯수:  1 \n",
            "\n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 14823475340577296736\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 16185556992\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 11765833760561082667\n",
            "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8EkWCjs5th5"
      },
      "source": [
        "## tf.data 사용법\n",
        "\n",
        "TensorFlow에서는 Dataset 이라는 built-in-API를 제공하고 있어서 위의 작업을 쉽게 처리할 수 있다. 이 포스트에서는 입력 파이프라인을 만들어서 모델에 데이터를 효율적으로 공급하는 방법을 살펴볼 것이다. 또한, 흔하게 볼 수 있는 예시를 다루면서 Dataset의 기본적인 메커니즘을 설명할 것이다.\n",
        "\n",
        "Dataset을 사용하려면 세 가지 단계를 거쳐야한다.\n",
        "\n",
        "  - 데이터셋 생성하기: 사용하려는 데이터로부터 Dataset 인스턴스를 만든다.\n",
        "  - Iterator(반복자) 생성하기. 생성된 데이터를 사용해서 Iterator 인스턴스를 만들어 Dataset을 iterate시킨다.\n",
        "  - 데이터 사용하기. 생성된 iterator를 사용해서 모델에 공급할 dataset으로부터 요소를 가져올 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK3YYGPE6DnQ"
      },
      "source": [
        "### 데이터 불러오기/Iterator(반복자) 생성하기\n",
        "\n",
        "일단 dataset안에 넣을 데이터가 필요하다.\n",
        "\n",
        "  - list \n",
        "  - numpy array\n",
        "  - tensor\n",
        "\n",
        "__from_tensor_slices()__\n",
        "\n",
        "It creates a Dataset whose elements are slices of the given tensors.\n",
        "\n",
        "  > \n",
        "  > from_tensor_slices(tensors)\n",
        "  >\n",
        "\n",
        "The given tensors are sliced along their first dimension. This operation preserves the structure of the input tensors, removing the first dimension of each tensor and using it as the dataset dimension. All input tensors must have the same size in their first dimensions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dakkhAZf-HKQ",
        "outputId": "610ab6d5-ae81-418c-af3b-5b16ce20cd24"
      },
      "source": [
        "# list에서 불러오기\n",
        "\n",
        "ds = tf.data.Dataset.from_tensor_slices([[1,2,3,4,5],\n",
        "                                         [5,6,7,8,9]])\n",
        "\n",
        "ds"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (5,), types: tf.int32>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHU-KR3n8Uct",
        "outputId": "700d62be-581f-4f14-c186-5044048eab69"
      },
      "source": [
        "import numpy as np\n",
        "# numpy에서 불러오기\n",
        "# create a random vector of shape (10,2)\n",
        "x = np.random.sample((10,2))\n",
        "# make a dataset from a numpy array\n",
        "ds = tf.data.Dataset.from_tensor_slices(x)\n",
        "\n",
        "print(type(ds))\n",
        "list(ds.as_numpy_iterator())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.data.ops.dataset_ops.TensorSliceDataset'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.28742414, 0.74769832]),\n",
              " array([0.65408172, 0.18287757]),\n",
              " array([0.19821726, 0.4241679 ]),\n",
              " array([0.85702003, 0.45553447]),\n",
              " array([0.26763705, 0.61746745]),\n",
              " array([0.77676629, 0.38342378]),\n",
              " array([0.29489216, 0.98122835]),\n",
              " array([0.11567539, 0.85496447]),\n",
              " array([0.80541762, 0.70710743]),\n",
              " array([0.47871613, 0.83781296])]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEBl3QQ29qb6"
      },
      "source": [
        "또한 데이터를 특성(feature)과 라벨(label)로 나누어 사용하는 경우처럼, 한 개 이상의 numpy 배열을 넣을 수도 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iGV8A_H9xbe",
        "outputId": "1f5ee0e8-56ec-4c0c-8913-b003945be64a"
      },
      "source": [
        "features, labels = (np.random.sample((10,2)), np.random.sample((10,1)))\n",
        "ds = tf.data.Dataset.from_tensor_slices((features,labels))\n",
        "\n",
        "print(type(ds))\n",
        "list(ds.as_numpy_iterator())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.data.ops.dataset_ops.TensorSliceDataset'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([0.59909138, 0.68485113]), array([0.40174538])),\n",
              " (array([0.62649744, 0.75297804]), array([0.35082164])),\n",
              " (array([0.3102005 , 0.95268443]), array([0.37910474])),\n",
              " (array([0.12716688, 0.23973209]), array([0.41891797])),\n",
              " (array([0.96790375, 0.45892965]), array([0.76406124])),\n",
              " (array([0.14100629, 0.46028756]), array([0.077457])),\n",
              " (array([0.25091007, 0.03379486]), array([0.19465404])),\n",
              " (array([0.67369105, 0.75833845]), array([0.31280578])),\n",
              " (array([0.45376893, 0.57216387]), array([0.05294739])),\n",
              " (array([0.43755944, 0.84518217]), array([0.10318423]))]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40IiRiqy_9OE",
        "outputId": "1e70e875-76b1-4c1b-b7d7-9d21670801e4"
      },
      "source": [
        "# tensor에서 불러오기\n",
        "ds = tf.data.Dataset.from_tensor_slices(tf.random.uniform([100, 2]))\n",
        "\n",
        "ds"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (2,), types: tf.float32>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyLpoMO_G7wY"
      },
      "source": [
        "### as_numpy_iterator() \n",
        "\n",
        "It returns an iterable over the elements of the dataset, with their tensors converted to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7G9nEWFFpHp",
        "outputId": "9e1f9f5b-b693-4968-d664-4d79ef723611"
      },
      "source": [
        "for num in ds.as_numpy_iterator():\n",
        "  print(num)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.06076014 0.75210893]\n",
            "[0.5227314  0.38314462]\n",
            "[0.37224174 0.33730292]\n",
            "[0.6399156 0.8571887]\n",
            "[0.13419497 0.31620705]\n",
            "[0.53104246 0.96876264]\n",
            "[0.77490366 0.8695797 ]\n",
            "[0.4010228  0.46247923]\n",
            "[0.2701255 0.4553125]\n",
            "[0.03831863 0.46635127]\n",
            "[0.6446265 0.6346551]\n",
            "[0.5888603  0.22811854]\n",
            "[0.6593696 0.1938585]\n",
            "[0.72324014 0.8723382 ]\n",
            "[0.06202817 0.78531754]\n",
            "[0.6805862 0.7266767]\n",
            "[0.80385864 0.28127277]\n",
            "[0.31983554 0.85509396]\n",
            "[0.48077726 0.38749194]\n",
            "[0.2623979  0.24601924]\n",
            "[0.4366157  0.48160756]\n",
            "[0.15135455 0.25945437]\n",
            "[0.7980974  0.21606481]\n",
            "[0.6158446  0.62218463]\n",
            "[0.36767685 0.31302786]\n",
            "[0.6627089 0.9398912]\n",
            "[0.87256455 0.7167152 ]\n",
            "[0.5833521 0.8268455]\n",
            "[0.5393417  0.05451369]\n",
            "[0.7467134 0.9027438]\n",
            "[0.70380163 0.6689832 ]\n",
            "[0.09288752 0.41362727]\n",
            "[0.21158862 0.6166409 ]\n",
            "[0.21115589 0.24647295]\n",
            "[0.3171779 0.0538553]\n",
            "[0.77096796 0.47211123]\n",
            "[0.93307364 0.6676769 ]\n",
            "[0.78123343 0.5420424 ]\n",
            "[0.20008767 0.8474612 ]\n",
            "[0.1856848  0.19465673]\n",
            "[0.13271916 0.39921916]\n",
            "[0.38916755 0.9233011 ]\n",
            "[0.15862751 0.208588  ]\n",
            "[0.41542435 0.57073665]\n",
            "[0.26937103 0.71653223]\n",
            "[0.12988663 0.40458822]\n",
            "[0.05600834 0.1565448 ]\n",
            "[0.7666081  0.53770375]\n",
            "[0.48829544 0.2733915 ]\n",
            "[0.27902293 0.24284959]\n",
            "[0.5574162  0.31712604]\n",
            "[0.89817655 0.89329994]\n",
            "[0.94116247 0.4107207 ]\n",
            "[0.4471519  0.24600875]\n",
            "[0.3049953 0.8553822]\n",
            "[0.25724804 0.19437945]\n",
            "[0.5749353  0.04268551]\n",
            "[0.15924048 0.01145518]\n",
            "[0.99485886 0.8200867 ]\n",
            "[0.19792712 0.41452408]\n",
            "[0.7461151 0.5193703]\n",
            "[0.12221038 0.42065954]\n",
            "[0.99909484 0.5279921 ]\n",
            "[0.4762311  0.66177475]\n",
            "[0.69293416 0.19212651]\n",
            "[0.6890099  0.36595285]\n",
            "[0.5741762 0.3610791]\n",
            "[0.7214105  0.22208786]\n",
            "[0.44376278 0.60558844]\n",
            "[0.7539774 0.6111671]\n",
            "[0.34274113 0.76831174]\n",
            "[0.19363558 0.19524074]\n",
            "[0.36775863 0.26077068]\n",
            "[0.06489682 0.31558502]\n",
            "[0.17150915 0.9546225 ]\n",
            "[0.70745695 0.41941   ]\n",
            "[0.50937414 0.11821437]\n",
            "[0.441082   0.10623693]\n",
            "[0.43349576 0.41214466]\n",
            "[0.6795062 0.9040748]\n",
            "[0.11008632 0.9633554 ]\n",
            "[0.15808141 0.94634604]\n",
            "[0.3469808  0.33293986]\n",
            "[0.5712141  0.49173212]\n",
            "[0.40445614 0.9323933 ]\n",
            "[0.22807014 0.48925006]\n",
            "[0.25524187 0.6083168 ]\n",
            "[0.47473133 0.25983787]\n",
            "[0.99784195 0.2012068 ]\n",
            "[0.5074631 0.8459226]\n",
            "[0.06708717 0.5364723 ]\n",
            "[0.66361606 0.98806393]\n",
            "[0.6284398 0.8976325]\n",
            "[0.5986978 0.6950487]\n",
            "[0.03674114 0.9638573 ]\n",
            "[0.59828794 0.55118537]\n",
            "[0.597931   0.94762254]\n",
            "[0.28645182 0.06478322]\n",
            "[0.03455591 0.33696532]\n",
            "[0.03399372 0.5567006 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXHoZLooGshL"
      },
      "source": [
        "### batch(): \n",
        "\n",
        "  It combines consecutive elements of this dataset into batches.\n",
        "\n",
        "  > \n",
        "  > batch(batch_size, drop_remainder=False)\n",
        "  >\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3oRDfk8IJw0",
        "outputId": "33c8e189-c4a4-4eba-c9b7-427c56093419"
      },
      "source": [
        "ds = tf.data.Dataset.range(10)\n",
        "ds = ds.batch(3)\n",
        "list(ds.as_numpy_iterator())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5]), array([6, 7, 8]), array([9])]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbQyqXxmIoBq",
        "outputId": "2caa5a47-804a-4949-9678-78cc7b3384f0"
      },
      "source": [
        "ds = tf.data.Dataset.range(10)\n",
        "ds = ds.batch(3, drop_remainder=True)\n",
        "list(ds.as_numpy_iterator())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5]), array([6, 7, 8])]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivogTx80KKcg"
      },
      "source": [
        "### filter()\n",
        "\n",
        "Filters this dataset according to predicate.\n",
        "\n",
        "  >\n",
        "  > filter(predicate)\n",
        "  >"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t72DmQnnKtyg",
        "outputId": "13a6ecdc-5822-4d85-addf-965c4fa72126"
      },
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices([1, 2, 3,4,5])\n",
        "ds = ds.filter(lambda x: x < 3)\n",
        "list(ds.as_numpy_iterator())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ogCtyxBLNYD",
        "outputId": "32cf0b51-397f-475d-a4b8-7c819e4fda4c"
      },
      "source": [
        "def filter_fn(x):\n",
        "  return tf.math.less(x, 3)\n",
        "\n",
        "ds = tf.data.Dataset.from_tensor_slices([1,2,3,4,5])\n",
        "ds = ds.filter(filter_fn)\n",
        "list(ds.as_numpy_iterator())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOQaSi6FI-2w"
      },
      "source": [
        "### apply()\n",
        "\n",
        "Applies a transformation function to this dataset.\n",
        "\n",
        "  >\n",
        "  > apply(transformation_func)\n",
        "  >"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IukcrjdJCRh",
        "outputId": "02c0dc86-902c-437e-deff-400a7d2090f1"
      },
      "source": [
        "dataset = tf.data.Dataset.range(100)\n",
        "def dataset_fn(ds):\n",
        "  return ds.filter(lambda x: x < 10)\n",
        "ds = dataset.apply(dataset_fn)\n",
        "list(ds.as_numpy_iterator())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNIMr-YITLPi"
      },
      "source": [
        "### shuffle()\n",
        "\n",
        "  >\n",
        "  > shuffle(buffer_size, seed=None, reshuffle_each_iteration=None)\n",
        "  >\n",
        "\n",
        "It randomly shuffles the elements of this dataset.\n",
        "\n",
        "This dataset fills a buffer with buffer_size elements, then randomly samples elements from this buffer, replacing the selected elements with new elements. For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0trJmd6DjqBZ"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k2u7pEjmo1m"
      },
      "source": [
        "## CNN with mnist using subclassing API  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "[MNIST 데이터셋](http://yann.lecun.com/exdb/mnist/)을 로드하여 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqFRS6K07jJs"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# 채널 차원을 추가합니다.\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1Evqx0S22r_"
      },
      "source": [
        "tf.data를 사용하여 데이터셋을 섞고 배치를 만듭니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Iu_quO024c2"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(10000).batch(32)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ68wASog_I"
      },
      "source": [
        "### 모델 서브클래싱(subclassing) API\n",
        "\n",
        "케라스(Keras)의 [모델 서브클래싱(subclassing) API](https://www.tensorflow.org/guide/keras#model_subclassing)를 사용하여 `tf.keras` 모델을 만듭니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3IKyzTCDNGo"
      },
      "source": [
        "class MyModel(Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.d2 = Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "model = MyModel()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGih-c2LgbJu"
      },
      "source": [
        "훈련에 필요한 옵티마이저(optimizer)와 손실 함수를 선택합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u48C9WQ774n4"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB6A1vcigsIe"
      },
      "source": [
        "모델의 손실과 성능을 측정할 지표를 선택합니다. 에포크가 진행되는 동안 수집된 측정 지표를 바탕으로 최종 결과를 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0MqHFb4F_qn"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy') # Calculates how often predictions match integer labels.\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4mEL65on-w"
      },
      "source": [
        "`tf.GradientTape`를 사용하여 모델을 훈련합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZACiVqA8KQV"
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8YT7UmFgpjV"
      },
      "source": [
        "이제 모델을 테스트합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIKdEzHAJGt7"
      },
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  predictions = model(images)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-2pkctU_Ci7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a569b5ab-5a9e-4b3d-bdf2-e4b0954768d7"
      },
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  template = '에포크: {}, 손실: {}, 정확도: {}, 테스트 손실: {}, 테스트 정확도: {}'\n",
        "  print (template.format(epoch+1,\n",
        "                         train_loss.result(),\n",
        "                         train_accuracy.result()*100,\n",
        "                         test_loss.result(),\n",
        "                         test_accuracy.result()*100))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "에포크: 1, 손실: 0.13577836751937866, 정확도: 95.79166412353516, 테스트 손실: 0.05823395028710365, 테스트 정확도: 98.02999877929688\n",
            "에포크: 2, 손실: 0.08848886936903, 정확도: 97.26333618164062, 테스트 손실: 0.05722919851541519, 테스트 정확도: 98.13999938964844\n",
            "에포크: 3, 손실: 0.06612000614404678, 정확도: 97.94944763183594, 테스트 손실: 0.05684208869934082, 테스트 정확도: 98.20333099365234\n",
            "에포크: 4, 손실: 0.052878715097904205, 정확도: 98.35208129882812, 테스트 손실: 0.060180000960826874, 테스트 정확도: 98.11750030517578\n",
            "에포크: 5, 손실: 0.04417392984032631, 정확도: 98.61566162109375, 테스트 손실: 0.06147143617272377, 테스트 정확도: 98.14399719238281\n",
            "에포크: 6, 손실: 0.03791283816099167, 정확도: 98.80999755859375, 테스트 손실: 0.06391113996505737, 테스트 정확도: 98.15833282470703\n",
            "에포크: 7, 손실: 0.03335427865386009, 정확도: 98.95238494873047, 테스트 손실: 0.06614696234464645, 테스트 정확도: 98.16285705566406\n",
            "에포크: 8, 손실: 0.029646120965480804, 정확도: 99.06791687011719, 테스트 손실: 0.0699506551027298, 테스트 정확도: 98.13999938964844\n",
            "에포크: 9, 손실: 0.026845399290323257, 정확도: 99.1540756225586, 테스트 손실: 0.07087111473083496, 테스트 정확도: 98.17333221435547\n",
            "에포크: 10, 손실: 0.024559341371059418, 정확도: 99.22616577148438, 테스트 손실: 0.07292332500219345, 테스트 정확도: 98.18900299072266\n",
            "에포크: 11, 손실: 0.02255372330546379, 정확도: 99.28909301757812, 테스트 손실: 0.0742477998137474, 테스트 정확도: 98.21363830566406\n",
            "에포크: 12, 손실: 0.020959436893463135, 정확도: 99.3388900756836, 테스트 손실: 0.07578426599502563, 테스트 정확도: 98.22083282470703\n",
            "에포크: 13, 손실: 0.019564511254429817, 정확도: 99.3826904296875, 테스트 손실: 0.07752623409032822, 테스트 정확도: 98.2223129272461\n",
            "에포크: 14, 손실: 0.018285347148776054, 정확도: 99.4228515625, 테스트 손실: 0.07943735271692276, 테스트 정확도: 98.230712890625\n",
            "에포크: 15, 손실: 0.01720401830971241, 정확도: 99.45722198486328, 테스트 손실: 0.08161752671003342, 테스트 정확도: 98.22733306884766\n",
            "에포크: 16, 손실: 0.016254542395472527, 정확도: 99.48739624023438, 테스트 손실: 0.08267580717802048, 테스트 정확도: 98.24687194824219\n",
            "에포크: 17, 손실: 0.015464951284229755, 정확도: 99.5125503540039, 테스트 손실: 0.0843680202960968, 테스트 정확도: 98.25529479980469\n",
            "에포크: 18, 손실: 0.01468489971011877, 정확도: 99.53722381591797, 테스트 손실: 0.08579674363136292, 테스트 정확도: 98.25833129882812\n",
            "에포크: 19, 손실: 0.013980217278003693, 정확도: 99.56008911132812, 테스트 손실: 0.08890526741743088, 테스트 정확도: 98.233154296875\n",
            "에포크: 20, 손실: 0.013383218087255955, 정확도: 99.57925415039062, 테스트 손실: 0.09140242636203766, 테스트 정확도: 98.2249984741211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4JfEh7kvx6m"
      },
      "source": [
        "훈련된 이미지 분류기는 이 데이터셋에서 약 98%의 정확도를 달성합니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFegQ-73l-Uu"
      },
      "source": [
        "### @tf.function으로 성능 향상하기\n",
        "\n",
        "@tf.fuctnion을 이해하기 위해서는 tensorflow 개발과정의 역사(?)를 조금 이해하셔야하는데요.\n",
        "tf 1.x 버전대에서는 그래프의 생성과 실행을 분리하고 값을 실행할때는 Session이라는 것을 열어서 값을 실행하는 형태였는데요. 이렇게 진행하다보니 값을 계산하고 싶을때마다 Session을 이용해서 실행을 해주어야만해서 프로그래밍 과정상에 불편함이 많았습니다.\n",
        "따라서 tf 2.x 버전대에서는 Session을 삭제하고 바로 값을 실행할 수 있는 Eager Execution이라는 것이 적용되었는데요. 따라서 값을 계산할때 별도의 Session을 열지 않고도 편리하게 진행할 수 있게 되었습니다.\n",
        "그럼 왜 굳이 tf 1.x대에서는 저렇게 복잡하게 그래프의 생성과 실행을 분리했느냐라고 생각해 볼 수 있는데요. 해당 형태가 성능상(=속도)의 이점이 있기 때문입니다.\n",
        "\n",
        "여기서 @tf.function 관련된 내용이 나오게 되는데요. def 위에 @tf.fucnction을 붙이면 마치 tf2.x 버전에서도 tf1.x 형태처럼 그래프 생성과 실행이 분리된 형태로 해당 함수내의 로직이 실행되게 됩니다. 따라서 상황에 따라서 성능이 약간 향상 될 수 있는데요.(=실행 속도가 약간 빨라질 수 있습니다.) 다만 해당 annoation을 붙이면 tf1.x처럼 해당 함수내의 값을 바로 계산해볼수 없어서 디버깅이 불편해질수 있습니다. 따라서 모든 로직에 대한 프로그래밍이 끝난 상태에서 @tf.fuction을 붙이는 것이 좋습니다.\n",
        "\n",
        "즉 정리하면\n",
        "1. @tf.fucntion을 붙이면 tf1.x 스타일로 해당 함수내의 로직이 동작한다.\n",
        "2. 따라서 상황에 따라 속도가 약간 빨라질 수 있다.\n",
        "3. 다만 해당 annotation을 붙이면 값을 바로 계산해볼수 없어서 모든 로직에 대한 프로그래밍이 끝난 뒤에 붙이는 것이 좋다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKBJJ7OsoW72",
        "outputId": "9081a77d-a402-4d42-bb4e-d5522fdb0300"
      },
      "source": [
        "@tf.function\n",
        "def add(a, b):\n",
        "  print(a,b)\n",
        "  # print('tf.variable 1 =',tf.Variable(3))\n",
        "  return a + b\n",
        "\n",
        "print('tf.variable 2 =',tf.Variable(3))\n",
        "add(tf.ones([2, 2]), tf.ones([2, 2]))  #  [[2., 2.], [2., 2.]]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.variable 2 = <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3>\n",
            "Tensor(\"a:0\", shape=(2, 2), dtype=float32) Tensor(\"b:0\", shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[2., 2.],\n",
              "       [2., 2.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO-VSijpyROR",
        "outputId": "f1a3817e-b1a1-4f33-f0f8-dbccac07e8a9"
      },
      "source": [
        "def add(a, b):\n",
        "  print(a,b)\n",
        "  print('tf.variable 1 =',tf.Variable(3))\n",
        "  return a + b\n",
        "\n",
        "print('tf.variable 2 =',tf.Variable(3))\n",
        "add(tf.ones([2, 2]), tf.ones([2, 2]))  #  [[2., 2.], [2., 2.]]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.variable 2 = <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3>\n",
            "tf.Tensor(\n",
            "[[1. 1.]\n",
            " [1. 1.]], shape=(2, 2), dtype=float32) tf.Tensor(\n",
            "[[1. 1.]\n",
            " [1. 1.]], shape=(2, 2), dtype=float32)\n",
            "tf.variable 1 = <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[2., 2.],\n",
              "       [2., 2.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt0vQkUyoX4C",
        "outputId": "6a80192d-3904-4c14-d698-0009cda4ad0f"
      },
      "source": [
        "v = tf.Variable(1.0)\n",
        "with tf.GradientTape() as tape:\n",
        "  result = add(v, 1.0)\n",
        "tape.gradient(result, v)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0> 1.0\n",
            "tf.variable 1 = <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}