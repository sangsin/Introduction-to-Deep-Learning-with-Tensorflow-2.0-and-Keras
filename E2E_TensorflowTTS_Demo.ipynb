{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E2E-TensorflowTTS Demo",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sangsin/Introduction-to-Deep-Learning-with-Tensorflow-2.0-and-Keras/blob/main/E2E_TensorflowTTS_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxRXlJhYewXN"
      },
      "source": [
        "# TensorflowTTS real time E2E-TTS demonstration\n",
        "\n",
        "This notebook provides a demonstration of the realtime E2E-TTS using TensorflowTTS\n",
        "\n",
        "- Github: https://github.com/TensorSpeech/TensorflowTTS\n",
        "- Audio samples: https://tensorspeech.github.io/TensorflowTTS/\n",
        "- Korean Colab: https://colab.research.google.com/drive/1ybWwOS5tipgPFttNulp77P6DAB5MtiuN?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT1B4yaVfR-V"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bXow5e8fRdx",
        "outputId": "7a58d5ca-f560-4f0b-b40e-59134f360723"
      },
      "source": [
        "import os\n",
        "!git clone https://github.com/TensorSpeech/TensorFlowTTS\n",
        "os.chdir(\"TensorFlowTTS\")\n",
        "!pip install  .\n",
        "os.chdir(\"..\")\n",
        "import sys\n",
        "sys.path.append(\"TensorFlowTTS/\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TensorFlowTTS'...\n",
            "remote: Enumerating objects: 10609, done.\u001b[K\n",
            "remote: Counting objects: 100% (319/319), done.\u001b[K\n",
            "remote: Compressing objects: 100% (161/161), done.\u001b[K\n",
            "remote: Total 10609 (delta 183), reused 234 (delta 153), pack-reused 10290\u001b[K\n",
            "Receiving objects: 100% (10609/10609), 133.30 MiB | 18.98 MiB/s, done.\n",
            "Resolving deltas: 100% (5123/5123), done.\n",
            "Processing /content/TensorFlowTTS\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting tensorflow-gpu==2.6.0\n",
            "  Downloading tensorflow_gpu-2.6.0-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 458.3 MB 11 kB/s \n",
            "\u001b[?25hCollecting tensorflow-addons>=0.10.0\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 33.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=38.5.1 in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS==0.0) (57.4.0)\n",
            "Collecting huggingface_hub==0.0.8\n",
            "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: librosa>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS==0.0) (0.8.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS==0.0) (0.10.3.post1)\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS==0.0) (3.2.2)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS==0.0) (3.13)\n",
            "Requirement already satisfied: tqdm>=4.26.1 in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS==0.0) (4.62.3)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS==0.0) (3.1.0)\n",
            "Collecting unidecode>=1.1.1\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 42.2 MB/s \n",
            "\u001b[?25hCollecting inflect>=4.1.0\n",
            "  Downloading inflect-5.3.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS==0.0) (0.22.2.post1)\n",
            "Collecting pyworld>=0.2.10\n",
            "  Downloading pyworld-0.3.0.tar.gz (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 42.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numba<=0.48\n",
            "  Downloading numba-0.48.0-1-cp37-cp37m-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 33.7 MB/s \n",
            "\u001b[?25hCollecting jamo>=0.4.1\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Collecting pypinyin\n",
            "  Downloading pypinyin-0.42.1-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 31.6 MB/s \n",
            "\u001b[?25hCollecting g2pM\n",
            "  Downloading g2pM-0.1.2.5-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 47.2 MB/s \n",
            "\u001b[?25hCollecting textgrid\n",
            "  Downloading TextGrid-1.5-py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS==0.0) (7.1.2)\n",
            "Collecting g2p_en\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 33.7 MB/s \n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface_hub==0.0.8->TensorFlowTTS==0.0) (4.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub==0.0.8->TensorFlowTTS==0.0) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface_hub==0.0.8->TensorFlowTTS==0.0) (2.23.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (2.6.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (2.6.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (1.6.3)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (5.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (2.6.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (0.37.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (0.2.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (0.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (3.17.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (1.12.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (1.19.5)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (1.41.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (3.3.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.10.0->TensorFlowTTS==0.0) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->TensorFlowTTS==0.0) (1.0.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->TensorFlowTTS==0.0) (0.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->TensorFlowTTS==0.0) (1.4.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->TensorFlowTTS==0.0) (1.5.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->TensorFlowTTS==0.0) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->TensorFlowTTS==0.0) (2.1.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->TensorFlowTTS==0.0) (21.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->TensorFlowTTS==0.0) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->TensorFlowTTS==0.0) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->TensorFlowTTS==0.0) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->TensorFlowTTS==0.0) (2.8.2)\n",
            "Collecting llvmlite<0.32.0,>=0.31.0dev0\n",
            "  Downloading llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.7.0->TensorFlowTTS==0.0) (1.4.4)\n",
            "Requirement already satisfied: cython>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyworld>=0.2.10->TensorFlowTTS==0.0) (0.29.24)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->TensorFlowTTS==0.0) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->TensorFlowTTS==0.0) (2.20)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub==0.0.8->TensorFlowTTS==0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub==0.0.8->TensorFlowTTS==0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub==0.0.8->TensorFlowTTS==0.0) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub==0.0.8->TensorFlowTTS==0.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS==0.0) (3.1.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons>=0.10.0->TensorFlowTTS==0.0) (2.7.1)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.7/dist-packages (from g2p_en->TensorFlowTTS==0.0) (3.2.5)\n",
            "Collecting distance>=0.1.3\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 43.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface_hub==0.0.8->TensorFlowTTS==0.0) (3.6.0)\n",
            "Building wheels for collected packages: TensorFlowTTS, pyworld, distance\n",
            "  Building wheel for TensorFlowTTS (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for TensorFlowTTS: filename=TensorFlowTTS-0.0-py3-none-any.whl size=131160 sha256=9dd8cb13bfa04d5112be9fa424200195f99886c0266954ec2e3b1cd3c4c167f5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2mqo8upi/wheels/e5/36/fb/a502156a232342e4818fe60e0d477ab8bb2b7d890030fdf93c\n",
            "  Building wheel for pyworld (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyworld: filename=pyworld-0.3.0-cp37-cp37m-linux_x86_64.whl size=608771 sha256=1351042988a50eb16ccbb2153c3b4fcc99f68d43dacfe792d6607ac213ffcced\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/7c/11/c775fffa0e1e7b05a6604b4323408a77f80fb4ab304d96b5c6\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16275 sha256=4ff8f2b7a5be560d72e9dbf4f390f7a59afc4f8bb203c173e39abc8fcd58bde4\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/10/1b/96fca621a1be378e2fe104cfb0d160bb6cdf3d04a3d35266cc\n",
            "Successfully built TensorFlowTTS pyworld distance\n",
            "Installing collected packages: llvmlite, numba, inflect, distance, unidecode, textgrid, tensorflow-gpu, tensorflow-addons, pyworld, pypinyin, jamo, huggingface-hub, g2pM, g2p-en, dataclasses, TensorFlowTTS\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Attempting uninstall: inflect\n",
            "    Found existing installation: inflect 2.1.0\n",
            "    Uninstalling inflect-2.1.0:\n",
            "      Successfully uninstalled inflect-2.1.0\n",
            "Successfully installed TensorFlowTTS-0.0 dataclasses-0.6 distance-0.1.3 g2p-en-2.1.0 g2pM-0.1.2.5 huggingface-hub-0.0.8 inflect-5.3.0 jamo-0.4.1 llvmlite-0.31.0 numba-0.48.0 pypinyin-0.42.1 pyworld-0.3.0 tensorflow-addons-0.14.0 tensorflow-gpu-2.6.0 textgrid-1.5 unidecode-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KwUTdAMO--O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4720e92-ca29-4fd7-ee8b-eb76b1c42fa0"
      },
      "source": [
        "!pip install git+https://github.com/repodiac/german_transliterate.git#egg=german_transliterate"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting german_transliterate\n",
            "  Cloning https://github.com/repodiac/german_transliterate.git to /tmp/pip-install-78sdn9ri/german-transliterate_5a05e0037ede4ff6a3893fba3dafed0e\n",
            "  Running command git clone -q https://github.com/repodiac/german_transliterate.git /tmp/pip-install-78sdn9ri/german-transliterate_5a05e0037ede4ff6a3893fba3dafed0e\n",
            "Collecting num2words\n",
            "  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words->german_transliterate) (0.6.2)\n",
            "Building wheels for collected packages: german-transliterate\n",
            "  Building wheel for german-transliterate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for german-transliterate: filename=german_transliterate-0.1.3-py3-none-any.whl size=20830 sha256=e80511581987774a72cbd000e7eed0674a7e59a8a88c7a7de2e6064abb746423\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-eqxfty9g/wheels/77/17/55/6c6d2d33bd2b3b8a3741e12b17f0b18278861f64858bbcc228\n",
            "Successfully built german-transliterate\n",
            "Installing collected packages: num2words, german-transliterate\n",
            "Successfully installed german-transliterate-0.1.3 num2words-0.5.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJHrsc1LQ4sz",
        "outputId": "5ff329d6-a774-44f0-9b8e-58563b1c6a3c"
      },
      "source": [
        "!pip install h5py==2.10.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires h5py~=3.1.0, but you have h5py 2.10.0 which is incompatible.\n",
            "tensorflow-gpu 2.6.0 requires h5py~=3.1.0, but you have h5py 2.10.0 which is incompatible.\u001b[0m\n",
            "Successfully installed h5py-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZLYVJ2kfxAz"
      },
      "source": [
        "## Download pretrained feature generation model\n",
        "\n",
        "You can select one from two models. Please only run the seletected model cells.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ImxaImZh3de"
      },
      "source": [
        "### (b) MelGAN + STFT Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6QsaE-uh6gf",
        "outputId": "f847dc15-71d4-4536-822f-ccf16bb7e054"
      },
      "source": [
        "print(\"Downloading MelGAN-STFT model...\")\n",
        "!gdown --id {\"1WB5iQbk9qB-Y-wO8BU6S2TnRiu4VU5ys\"} -O melgan.stft-2M.h5\n",
        "!gdown --id {\"1OqdrcHJvtXwNasEZP7KXZwtGUDXMKNkg\"} -O melgan.stft_config.yml"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading MelGAN-STFT model...\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WB5iQbk9qB-Y-wO8BU6S2TnRiu4VU5ys\n",
            "To: /content/melgan.stft-2M.h5\n",
            "17.1MB [00:00, 72.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OqdrcHJvtXwNasEZP7KXZwtGUDXMKNkg\n",
            "To: /content/melgan.stft_config.yml\n",
            "100% 1.77k/1.77k [00:00<00:00, 5.41MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D9cOkKni_Pu"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKWOHNekjoX_"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# patch for  'Failed to get convolution algorithm.' error \n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.compat.v1.Session(config=config)\n",
        "\n",
        "import yaml\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import IPython.display as ipd\n",
        "\n",
        "from tensorflow_tts.inference import TFAutoModel\n",
        "from tensorflow_tts.inference import AutoConfig\n",
        "from tensorflow_tts.inference import AutoProcessor"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYzz_JkjjbSb"
      },
      "source": [
        "### (a) Tacotron 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LUmgY69inlf",
        "outputId": "b6ba50ff-64dc-473b-c680-92bf4900b5db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "tacotron2 = TFAutoModel.from_pretrained(\"tensorspeech/tts-tacotron2-ljspeech-en\", name=\"tacotron2\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a492ed53a326>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtacotron2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tensorspeech/tts-tacotron2-ljspeech-en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tacotron2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_tts/inference/auto_model.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_path, config, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpretrained_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\".h5\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpretrained_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_tts/inference/savable_models.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0minput_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mspeaker_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeaker_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_tts/inference/savable_models.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeaker_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeaker_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node encoder/conv_batch_norm/tf_tacotron_conv_batch_norm_10/conv_._0/conv1d (defined at /usr/local/lib/python3.7/dist-packages/tensorflow_tts/models/tacotron2.py:110) ]]\n\t [[decoder/while/loop_body_control/_88/_45]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node encoder/conv_batch_norm/tf_tacotron_conv_batch_norm_10/conv_._0/conv1d (defined at /usr/local/lib/python3.7/dist-packages/tensorflow_tts/models/tacotron2.py:110) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_inference_19040]\n\nFunction call stack:\ninference -> inference\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88Dnvb83kJeX"
      },
      "source": [
        "### (b) FastSpeech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML_v-BM3kGwr"
      },
      "source": [
        "fastspeech = TFAutoModel.from_pretrained(\"tensorspeech/tts-fastspeech-ljspeech-en\", name=\"fastspeech\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78pHAU5LAB8i"
      },
      "source": [
        "### (c) FastSpeech2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlqrwBh0AFKD"
      },
      "source": [
        "fastspeech2 = TFAutoModel.from_pretrained(\"tensorspeech/tts-fastspeech2-ljspeech-en\", name=\"fastspeech2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_2YS4_8knt6"
      },
      "source": [
        "### (d) MelGAN Original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFbx247dkgGz"
      },
      "source": [
        "melgan = TFAutoModel.from_pretrained(\"tensorspeech/tts-melgan-ljspeech-en\", name=\"melgan\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcUeu-BylIDB"
      },
      "source": [
        "### (e) MelGAN STFT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F11-o-QrlBzN"
      },
      "source": [
        "melgan_stft_config = AutoConfig.from_pretrained('TensorFlowTTS/examples/melgan_stft/conf/melgan_stft.v1.yaml')\n",
        "melgan_stft = TFAutoModel.from_pretrained(\n",
        "    config=melgan_stft_config,\n",
        "    pretrained_path=\"melgan.stft-2M.h5\",\n",
        "    name=\"melgan_stft\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbnKxE5BlVAf"
      },
      "source": [
        "### (f) Multi-band MelGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wzU9yQElSDK"
      },
      "source": [
        "mb_melgan = TFAutoModel.from_pretrained(\"tensorspeech/tts-mb_melgan-ljspeech-en\", name=\"mb_melgan\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dWX0JNslwHg"
      },
      "source": [
        "## Inference\n",
        "- The first time model run inference will very slow cause by @tf.function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jUYfVKomNm5"
      },
      "source": [
        "processor = AutoProcessor.from_pretrained(\"tensorspeech/tts-tacotron2-ljspeech-en\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktHeraInlrsl"
      },
      "source": [
        "def do_synthesis(input_text, text2mel_model, vocoder_model, text2mel_name, vocoder_name):\n",
        "  input_ids = processor.text_to_sequence(input_text)\n",
        "\n",
        "  # text2mel part\n",
        "  if text2mel_name == \"TACOTRON\":\n",
        "    _, mel_outputs, stop_token_prediction, alignment_history = text2mel_model.inference(\n",
        "        tf.expand_dims(tf.convert_to_tensor(input_ids, dtype=tf.int32), 0),\n",
        "        tf.convert_to_tensor([len(input_ids)], tf.int32),\n",
        "        tf.convert_to_tensor([0], dtype=tf.int32)\n",
        "    )\n",
        "  elif text2mel_name == \"FASTSPEECH\":\n",
        "    mel_before, mel_outputs, duration_outputs = text2mel_model.inference(\n",
        "        input_ids=tf.expand_dims(tf.convert_to_tensor(input_ids, dtype=tf.int32), 0),\n",
        "        speaker_ids=tf.convert_to_tensor([0], dtype=tf.int32),\n",
        "        speed_ratios=tf.convert_to_tensor([1.0], dtype=tf.float32),\n",
        "    )\n",
        "  elif text2mel_name == \"FASTSPEECH2\":\n",
        "    mel_before, mel_outputs, duration_outputs, _, _ = text2mel_model.inference(\n",
        "        tf.expand_dims(tf.convert_to_tensor(input_ids, dtype=tf.int32), 0),\n",
        "        speaker_ids=tf.convert_to_tensor([0], dtype=tf.int32),\n",
        "        speed_ratios=tf.convert_to_tensor([1.0], dtype=tf.float32),\n",
        "        f0_ratios=tf.convert_to_tensor([1.0], dtype=tf.float32),\n",
        "        energy_ratios=tf.convert_to_tensor([1.0], dtype=tf.float32),\n",
        "    )\n",
        "  else:\n",
        "    raise ValueError(\"Only TACOTRON, FASTSPEECH, FASTSPEECH2 are supported on text2mel_name\")\n",
        "\n",
        "  # vocoder part\n",
        "  if vocoder_name == \"MELGAN\" or vocoder_name == \"MELGAN-STFT\":\n",
        "    audio = vocoder_model(mel_outputs)[0, :, 0]\n",
        "  elif vocoder_name == \"MB-MELGAN\":\n",
        "    audio = vocoder_model(mel_outputs)[0, :, 0]\n",
        "  else:\n",
        "    raise ValueError(\"Only MELGAN, MELGAN-STFT and MB_MELGAN are supported on vocoder_name\")\n",
        "\n",
        "  if text2mel_name == \"TACOTRON\":\n",
        "    return mel_outputs.numpy(), alignment_history.numpy(), audio.numpy()\n",
        "  else:\n",
        "    return mel_outputs.numpy(), audio.numpy()\n",
        "\n",
        "def visualize_attention(alignment_history):\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  fig = plt.figure(figsize=(8, 6))\n",
        "  ax = fig.add_subplot(111)\n",
        "  ax.set_title(f'Alignment steps')\n",
        "  im = ax.imshow(\n",
        "      alignment_history,\n",
        "      aspect='auto',\n",
        "      origin='lower',\n",
        "      interpolation='none')\n",
        "  fig.colorbar(im, ax=ax)\n",
        "  xlabel = 'Decoder timestep'\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.ylabel('Encoder timestep')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "def visualize_mel_spectrogram(mels):\n",
        "  mels = tf.reshape(mels, [-1, 80]).numpy()\n",
        "  fig = plt.figure(figsize=(10, 8))\n",
        "  ax1 = fig.add_subplot(311)\n",
        "  ax1.set_title(f'Predicted Mel-after-Spectrogram')\n",
        "  im = ax1.imshow(np.rot90(mels), aspect='auto', interpolation='none')\n",
        "  fig.colorbar(mappable=im, shrink=0.65, orientation='horizontal', ax=ax1)\n",
        "  plt.show()\n",
        "  plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uv_QngUmFbK"
      },
      "source": [
        "input_text = \"Bill got in the habit of asking himself “Is that thought true?” And if he wasn’t absolutely certain it was, he just let it go.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiCe8nU3qJa6"
      },
      "source": [
        "# setup window for tacotron2 if you want to try\n",
        "tacotron2.setup_window(win_front=10, win_back=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2Mw68kuocN0"
      },
      "source": [
        "### (a) Tacotron2 + MELGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ChvXMc8mF7K"
      },
      "source": [
        "mels, alignment_history, audios = do_synthesis(input_text, tacotron2, melgan, \"TACOTRON\", \"MELGAN\")\n",
        "visualize_attention(alignment_history[0])\n",
        "visualize_mel_spectrogram(mels[0])\n",
        "ipd.Audio(audios, rate=22050)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EojaL8UpWv7"
      },
      "source": [
        "### (b) Tacotron2 + MELGAN-STFT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYsCG-10pH31"
      },
      "source": [
        "mels, alignment_history, audios = do_synthesis(input_text, tacotron2, melgan_stft, \"TACOTRON\", \"MELGAN-STFT\")\n",
        "visualize_attention(alignment_history[0])\n",
        "visualize_mel_spectrogram(mels[0])\n",
        "ipd.Audio(audios, rate=22050)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n-qJ8WrprGC"
      },
      "source": [
        "### (c) Tacotron2 + MB-MELGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfY8bDJUpjFe"
      },
      "source": [
        "mels, alignment_history, audios = do_synthesis(input_text, tacotron2, mb_melgan, \"TACOTRON\", \"MB-MELGAN\")\n",
        "visualize_attention(alignment_history[0])\n",
        "visualize_mel_spectrogram(mels[0])\n",
        "ipd.Audio(audios, rate=22050)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8kKkMtlqdJS"
      },
      "source": [
        "### (d) FastSpeech + MB-MELGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP1N64dcp4Nf"
      },
      "source": [
        "mels, audios = do_synthesis(input_text, fastspeech, mb_melgan, \"FASTSPEECH\", \"MB-MELGAN\")\n",
        "visualize_mel_spectrogram(mels[0])\n",
        "ipd.Audio(audios, rate=22050)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec26VNi8qr_5"
      },
      "source": [
        "### (e) FastSpeech + MELGAN-STFT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8hUSNeeqk42"
      },
      "source": [
        "mels, audios = do_synthesis(input_text, fastspeech, melgan_stft, \"FASTSPEECH\", \"MELGAN-STFT\")\n",
        "visualize_mel_spectrogram(mels[0])\n",
        "ipd.Audio(audios, rate=22050)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRhpoCR7rCLt"
      },
      "source": [
        "### (f) FastSpeech + MELGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL4U5qHMqvwr"
      },
      "source": [
        "mels, audios = do_synthesis(input_text, fastspeech, melgan, \"FASTSPEECH\", \"MELGAN\")\n",
        "visualize_mel_spectrogram(mels[0])\n",
        "ipd.Audio(audios, rate=22050)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzgY8pu1A3OA"
      },
      "source": [
        "### (g) FastSpeech2 + MB-MELGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0LczJ21rEyQ"
      },
      "source": [
        "mels, audios = do_synthesis(input_text, fastspeech2, mb_melgan, \"FASTSPEECH2\", \"MB-MELGAN\")\n",
        "visualize_mel_spectrogram(mels[0])\n",
        "ipd.Audio(audios, rate=22050)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXDxzTFBBxjH"
      },
      "source": [
        "### (h) FastSpeech2 + MELGAN-STFT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtACB6aeBxum"
      },
      "source": [
        "mels, audios = do_synthesis(input_text, fastspeech2, melgan_stft, \"FASTSPEECH2\", \"MELGAN-STFT\")\n",
        "visualize_mel_spectrogram(mels[0])\n",
        "ipd.Audio(audios, rate=22050)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmtjEWpKBx1s"
      },
      "source": [
        "### (i) FastSpeech2 + MELGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vILWb-gRBx9E"
      },
      "source": [
        "mels, audios = do_synthesis(input_text, fastspeech2, melgan, \"FASTSPEECH2\", \"MELGAN\")\n",
        "visualize_mel_spectrogram(mels[0])\n",
        "ipd.Audio(audios, rate=22050)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEVHO4hHyp92"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}